import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

import pickle

from tensorflow import keras

opetus_ja_vastetiedot=pickle.load( open( "ImageSegmentation/Data/opetustiedot.p", "rb" ) )

images = opetus_ja_vastetiedot[0]
masks =  opetus_ja_vastetiedot[1]

#Scaling
images = images / 255 
masks = masks / 255

#Adding a dimension
images = np.expand_dims(images, axis=3)
masks = np.expand_dims(masks, axis=3)

#CONFIG
image_shape = images[0].shape
IMG_HEIGHT = image_shape[0]
IMG_WIDTH = image_shape[1]
IMG_CHANNELS = image_shape[2]

# I really want to rewrite this.
train_ds=[]
val_ds=[]
for i in range(200): # Why in range(200)??????
    if np.random.rand()<0.2:
        train_ds.append(i)
        if np.random.rand()<0.0:
            masks[i,50:60,50:60]=1
    else:
        val_ds.append(i)

traind_ds=np.array(train_ds)
val_ds=np.array(val_ds)

# Model def here 
def make_model(input_shape, num_classes):
    inputs = keras.Input(shape=input_shape)

    # Contracting Path
    x =keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)
    c1_residue = x
    x =keras.layers.MaxPooling2D((2, 2))(x)
    
    x =keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
    c2_residue = x
    x =keras.layers.MaxPooling2D((2, 2))(x)

    x =keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
    c3_residue = x
    x =keras.layers.MaxPooling2D((2, 2))(x)

    x =keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)
    c4_residue = x
    x =keras.layers.MaxPooling2D((2, 2))(x)

    x =keras.layers.Conv2D(1024, (3, 3), activation='relu', padding='same')(x)
    
    # Expansive Path    
    x =keras.layers.Conv2DTranspose(512, (2, 2), strides=(2, 2), padding='same')(x)
    x =keras.layers.Concatenate()([x, c4_residue])
    x =keras.layers.Conv2D(512, (3, 3), activation='relu', padding='same')(x)
    
    x =keras.layers.Conv2DTranspose(256, (2, 2), strides=(2, 2), padding='same')(x)
    x =keras.layers.Concatenate()([x, c3_residue])
    c7 =keras.layers.Conv2D(256, (3, 3), activation='relu', padding='same')(x)
   
    x =keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(x)
    x =keras.layers.Concatenate()([x, c2_residue])
    x =keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)
   
    x =keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(x)
    x =keras.layers.Concatenate()([x, c1_residue])
    x =keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)


    outputs = keras.layers.Conv2D(num_classes, (1, 1), activation="sigmoid")(x)
    return keras.Model(inputs, outputs)

model = make_model(input_shape=image_shape, num_classes=1)
keras.utils.plot_model(model, show_shapes=True) #Making the .png of a model
quit()
#Model Config
epochs = 50
#Saving as *.weights.h5 according to Keras3 recommendation
#https://github.com/keras-team/keras-io/issues/1568
callbacks = [
    keras.callbacks.ModelCheckpoint("teras.weights.h5", monitor='val_loss', verbose = 1, save_best_only = True, mode = 'min'),
    keras.callbacks.EarlyStopping(patience = 30, verbose = 1),
    ]
model.compile(
    optimizer=keras.optimizers.legacy.Adam(1e-3),
    loss = "binary_crossentropy",
    metrics=["accuracy"], #Maybe Loss is better?
)
history = model.fit(
    images[train_ds],masks[train_ds],
    epochs=epochs,
    callbacks=callbacks,
    validation_data=(images[val_ds],masks[val_ds]),
)

history_dict = history.history
loss_values = history_dict["loss"]
val_loss_values = history_dict["val_loss"]
epochs = range(1, len(loss_values) + 1)
plt.plot(epochs, loss_values, "bo", label="Training loss")
plt.plot(epochs, val_loss_values, "b", label="Validation loss")
plt.title("Training and validation loss")
plt.xlabel("Epochs")
plt.ylabel("Loss")
plt.legend()
plt.show()

plt.clf() #matplotlib figure clearing
acc = history_dict["accuracy"]
val_acc = history_dict["val_accuracy"]
plt.plot(epochs, acc, "bo", label="Training acc")
plt.plot(epochs, val_acc, "b", label="Validation acc")
plt.title("Training and validation accuracy")
plt.xlabel("Epochs")
plt.ylabel("Accuracy")
plt.legend()
plt.show()